<html lang="en">
<head>
    <meta charset="utf-8">
    <title>TroublingGAN</title>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="description" content="TroublingGAN is a StyleGAN model that generates visually ambiguous visuals representing 'troubling times'. With the goal to create a different kind of knowledge about this elusive concept, we used the generative neural network to process uncategorised news photography from 2020, define specific visual features and generate new examples of recognised patterns from inside the dataset. TroublingGAN is able to derive an essence of 'troubling times' and project the affective value of news photography (as used in our training dataset) onto generated visual outputs.">
    <link rel="icon" type="image/jpeg" href="favicon.jpg" />

    <meta property="twitter:account_id" content="994910988" />
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@lenkahamosova">
    <meta name="twitter:creator" content="@lenkahamosova">
    <meta name="twitter:title" content="TroublingGAN">
    <meta name="twitter:description" content="TroublingGAN is a StyleGAN model that generates visually ambiguous visuals representing 'troubling times'. With the goal to create a different kind of knowledge about this elusive concept, we used the generative neural network to process uncategorised news photography from 2020, define specific visual features and generate new examples of recognised patterns from inside the dataset. TroublingGAN is able to derive an essence of 'troubling times' and project the affective value of news photography (as used in our training dataset) onto generated visual outputs.">
    <meta name="twitter:image:src" content="https://troublinggan.hamosova.com/share.jpg">
    <meta name="twitter:image:width" content="400">
    <meta name="twitter:image:height" content="400">
    <meta name="twitter:domain" content="troublinggan.hamosova.com">

    <meta property="og:title" content="TroublingGAN" />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://troublinggan.hamosova.com" />
    <meta property="og:image" content="https://troublinggan.hamosova.com/share.jpg" />
    <meta property="og:site_name" content="TroublingGAN" />
    <meta property="og:description" content="TroublingGAN is a StyleGAN model that generates visually ambiguous visuals representing 'troubling times'. With the goal to create a different kind of knowledge about this elusive concept, we used the generative neural network to process uncategorised news photography from 2020, define specific visual features and generate new examples of recognised patterns from inside the dataset. TroublingGAN is able to derive an essence of 'troubling times' and project the affective value of news photography (as used in our training dataset) onto generated visual outputs.">

    <style>
        @font-face {
          font-family: 'Lora';
          font-style: normal;
          font-weight: 400;
          font-display: swap;
          src: url('lora.woff') format('woff');
          unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
        }
        @font-face {
          font-family: 'Lora';
          font-style: italic;
          font-weight: 400;
          font-display: swap;
          src: url('lora-italic.woff') format('woff');
          unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
        }
        body,
        html {
            display: flex;
            justify-content: center;
            background-color: #202124;
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            position: relative;
            font-family: 'Lora', serif;
            font-size: 1.1em;
            overflow-x: hidden;
            color: white;
        }
        div {
            width: 40%;
            margin: 5%;
        }
        a {
            color: white;
        }
        p {
            line-height: 150%;
        }
    </style>
</head>

<body>
    <div>
      <h1>TroublingGAN</h1>
      <p><i>TroublingGAN</i> je model StyleGAN︎︎︎︎, který generuje vizuálně nejednoznačné obrazu zobrazující "znepokojivou dobu". Motivací k vytvoření tohoto zdánlivě nedokonalého generativního modelu byla snaha dospět k novému typu poznání vágního pojmu "znepokojivé doby" pomocí perspektivy neuronových sítí.</p>
      <p>Podle Mattea Pasquinelliho a Vladana Jolera lze neuronové sítě považovat za "nástroj poznání" (2020). Takový nástroj se skládá z pozorovaného objektu (vstupní soubor fotografií), nástroje pro pozorování (algoritmus hlubokého strojového učení) a konečné reprezentace (statistický model). Ve své eseji <i>The Nooscope Manifested</i> používají analogii optického média, aby vysvětlili, jak tento "nástroj poznání" funguje:</p>
      <p style="margin-left: 3em;">"informační tok strojového učení je jako paprsek světla, který je promítán skrze soubor dat, komprimován algoritmem a rozptýlen do světa optikou statistického modelu" (Pasquinelli a Joler 2020)</p>
      <p>Při takto střízlivém výkladu "magických schopností" umělé inteligence je těžké uvěřit, že z generativního modelu může vzejít něco nového - nějaké nové znalosti. Neuronová síť jako nástroj poznávání však dokáže analyzovat velké množství dat nejen rychleji než člověk, ale také jinak. Takový model StyleGAN se pak stává nástrojem pro vizuální znázornění vzorů v pozorovaném objektu (datasetu), které neuronová síť rozpoznala, což nám umožňuje podívat se na soubor dat z jiné perspektivy. Tyto nové poznatky jsou však velmi jemné a lze je vnímat především prostřednictvím emocí.</p>
      <p>Vstupním souborem dat pro <i>TroublingGAN</i> byla sbírka fotografií zpravodajské agentury Reuters pro rok 2020. Použité fotografie (až na několik neutrálních výjimek) dokumentují výhradně přírodní katastrofy, sociální nepokoje, politické protesty, vojenské konflikty a probíhající pandemii. Mnohé z těchto fotografií byly v médiích použity opakovaně, recyklovány v podobě ilustrační fotografie, jejímž primárním účelem bylo vyvolat emoce a umocnit tak naléhavost sdělované informace. Původně dokumentární fotografie se tak mění na "stock photo".</p>
      <p>Problémem se stává rozlišení mezi dokumentární fotografií, která se vztahuje k zobrazovanému kontextu, a snímky, které se používají pouze pro svou afektivní kvalitu. I v těchto dnech, v souvislosti s probíhající vojenskou invazí na Ukrajině, kolují na internetu snímky jako svědectví o krutosti ruské armády, které se postupně mění v ilustrační materiál, čímž se znehodnocuje zaznamenaný obsah a konkrétní příběhy konkrétních lidí. Jako konzumenti těchto obrazů začínáme být k těmto vizuálním informacím postupně lhostejní a obrazy utrpení se na sociálních sítích prolínají s banálními obrazy každodenního života. Pomohly by v této situaci generované, vizuálně nejednoznačné vizuály jako náhrada za neetické použití fotožurnalistiky jako ilustrační fotografie?</p>
      <p>Generativní neuronová síť se učí na základě vstupního datasetu generovat nové syntetické vizuály definováním jednotlivých vizuálních rysů a vlastností rozpoznaných v datasetu. Vzhledem k vysoké variabilitě scén zachycených na fotografiích není neuronová síť schopna tímto způsobem dosáhnout fotorealismu, což však není vnímáno jako nedokonalost. Navzdory absenci konkrétních objektů a scén v generovaných výstupech <i>TroublingGAN</i>-u tyto vizuálně nejednoznačné obrazy stále zvláštním způsobem připomínají fotografii. To je pro lidské oko velmi matoucí. Mysl se neustále snaží přiřadit těmto nejednoznačným kompozicím, jakkoli abstraktním, nějaký význam. Přisouzený význam nebo interpretace se však stává dynamickou a neustále se měnící, a proto na diváka nakonec působí atmosféra a emocionální náboj. Není tu nikdo, kdo by určoval kompozici, usměrňoval směr pohledu nebo odkaz, který má obraz komunikovat. Přesto vnímáme, že tyto obrazy patří k sobě, že nesou společné poselství. Jsme schopni z nich vyčíst něco o povaze předmětu našeho pozorování - fotografiích, které vizuálně představují "znepokojivou dobu"?</p>
      <p>Výsledný model <i>TroublingGAN</i> dokáže odvodit esenci "znepokojivé doby" a promítnout afektivní kvalitu použité žurnalistiké fotografie do generovaných výstupů. Co se vlastně při takové projekci děje? Můžeme to nazvat kontemplací nad zobrazeným tématem? Je možné takový proces marné apofenie použít jako metodu kritické reflexe?</p>
      <p><i>TroublingGAN</i> byl vytvořen jako umělecko-výzkumný nástroj, který má pomoci vytvořit jiný způsob nahlížení na obrazy použité v datasetu. <i>TroublingGAN</i> zároveň funguje jako metafora začarovaného kruhu, v němž se dnes nacházíme. Pokud nezměníme "dataset", tj. vstupní data pro naše uvažování o světě a způsob, jakým navrhujeme jeho řešení, uvízneme v generování nových verzí stejných problémů. Totéž platí pro utopické vize umělé inteligence, která může být jen tak osvícená, jak kvalitní vstupní data jí dokážeme nabídnout, zbavená všech kulturních stereotypů, předsudků a opakujících se lidských chyb.</p>
      <p style="font-size: 0.7em;">Pasquinelli, M. and Joler, V. (2020) ‘The Nooscope manifested: AI as instrument of knowledge extractivism’, AI &amp; SOCIETY [Preprint]. doi:10.1007/s00146-020-01097-6.</p>
      <p><a href="index.html">zpátky</a>
    </div>
    <div>
      <h1>TroublingGAN</h1>
      <p><i>TroublingGAN</i> is a StyleGAN︎︎︎ model that generates a visually ambiguous images depicting  "troubling times". The motivation for creating this seemingly imperfect generative model was to arrive at a new type of understanding of the vague notion of "troubling times" using a neural network perspective.</p>
      <p>According to Matteo Pasquinelli and Vladan Joler, neural networks can be considered a "instrument of knowledge" (2020). Such an instrument consists of an observed object (a dataset of photographs), an observation tool (a deep learning algorithm) and a final representation (a statistical model). In their essay <i>The Nooscope Manifested</i>, they use the analogy of an optical medium to explain how this "instrument of knowledge" works:</p>
      <p style="margin-left: 3em;">"the information flow of machine learning is like a light beam that is projected by the training data, compressed by the algorithm and diffracted towards the world by the lens of the statistical model" (Pasquinelli and Joler, 2020)</p>
      <p>With such a sober interpretation of the "magical powers" of AI, it is hard to believe that anything new - any new knowledge - can come out of the generative model. However, a neural network as a cognitive tool can analyze large amounts of data not only faster than a human, but also in a different way. Such a StyleGAN model then becomes a tool to visually represent the patterns in the observed object (dataset) that the neural network has recognized, allowing us to look at the dataset from a different perspective. However, these new insights are very subtle and can be perceived primarily through emotion.</p>
      <p>The input dataset for <i>TroublingGAN</i> was the Reuters collection “Photos of the Week” for the year 2020. The photographs used (with a few neutral exceptions) exclusively document natural disasters, social unrest, political protests, military conflicts and ongoing pandemic. Many of these photographs have been reused in the media, recycled in the form of illustrative photography, the primary purpose of which was to evoke emotion and thus heighten the urgency of the message being conveyed. Thus, originally a documentary photograph becomes a "stock photo".</p>
      <p>The distinction between documentary photography, which relates to the context being depicted, and images that are used only for their affective quality becomes a problem. Even these days, in the context of the ongoing military invasion in Ukraine, images are circulating on the internet as testimony to the cruelty of the Russian army, which are gradually being turned into illustrative material, thereby devaluing the recorded content and the specific stories of particular people. As consumers of these images, we are gradually becoming indifferent to this visual information, and images of suffering are interspersed on social media with banal images of everyday life. In this situation, would generated, visually ambiguous visuals help as a substitute for the unethical use of photojournalism as illustrative photography?</p>
      <p>The generative neural network learns to generate new synthetic visuals based on the input dataset by defining individual visual features and properties recognized in the dataset. Due to the high variability of scenes captured in photographs, the neural network is not able to achieve photorealism in this way, but this is not perceived as an imperfection. Despite the absence of specific objects and scenes in the generated <i>TroublingGAN</i> outputs, these visually ambiguous images still resemble a photograph in some way. This is very confusing to the human eye. The mind is constantly trying to impose some meaning to these ambiguous compositions, however abstract. The assigned meaning or interpretation, however, becomes dynamic and ever-changing, and therefore the atmosphere and emotional charge ultimately affects the viewer. There is no one to determine the composition, direct the direction of the gaze or the message the image is meant to communicate. Yet we sense that these images belong together, that they carry a common message. Are we able to read from them something about the nature of the object of our observation - photographs that visually represent  "troubling times"?</p>
      <p>The resulting <i>TroublingGAN</i> model can detect the essence of "troubling times" and project the affective quality of the journalistic photography used into the generated outputs. What actually happens in such a projection? Can we call it a contemplation of the depicted theme? Can such a process of futile apophenia be used as a method of critical reflection?</p>
      <p><i>TroublingGAN</i> was created as an artistic research tool to help create a different way of looking at the images used in the dataset. <i>TroublingGAN</i> also functions as a metaphor for the vicious circle we find ourselves in today. If we don't change the "dataset", i.e. the input data for our thinking about the world and the way we design solutions for it, we get stuck in generating new versions of the same problems. The same goes for utopian visions of artificial intelligence, which can only be as enlightened as the quality of the input data we can offer it, free of all cultural stereotypes, prejudices and repetitive human errors.</p>
      <p style="font-size: 0.7em;">Pasquinelli, M. and Joler, V. (2020) ‘The Nooscope manifested: AI as instrument of knowledge extractivism’, AI &amp; SOCIETY [Preprint]. doi:10.1007/s00146-020-01097-6.</p>
      <p style="padding-bottom: 5em;"><a href="index.html">back</a>
    </div>
</body>

</html>
